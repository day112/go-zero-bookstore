global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.                            
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.                                    
    # scrape_timeout is set to the global default (10s).

# Alertmanager configuration                                                                                                    
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.                                 
rule_files:
# - "first_rules.yml"
# - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:                                                             
# Here it's Prometheus itself.                                                                                                  
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.                               
  - job_name: 'prometheus'

      # metrics_path defaults to '/metrics'
      # scheme defaults to 'http'.

    static_configs:
#      - targets: ['192.168.0.24:9090']
      - targets: ['192.168.31.132:8090', '192.168.31.132:8091', '192.168.31.132:8898']  # 服务器上使用内网ip
      - "labels": {
        "job": "bookstore-api",
        "app": "bookstore-api",
        "env": "test",
        "instance": "192.168.31.132:31443"
      }

  # 采集node exporter监控数据
  - job_name: 'node'
    static_configs:
      - targets: ['192.168.31.132:9100']  # 服务器上使用内网ip